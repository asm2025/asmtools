[package]
name = "kalosm-language-model"
version = "0.2.1"
edition = "2021"
description = "A common interface for language models/transformers "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["ai", "llm", "llama", "mistral", "nlp"]

[dependencies]
futures-util = "0"
llm-samplers = { workspace = true }
log = "0"
rand = "0"
tokio = { version = "1", features = ["sync"] }
serde = { version = "1", features = ["derive"], optional = true }
once_cell = "1"
anyhow = "1"
tracing = "0"
async-openai = { version = "0", optional = true }
async-trait = "0"
candle-core.workspace = true
kalosm-sample.workspace = true
kalosm-common.workspace = true
kalosm-streams.workspace = true
rayon = "1"
postcard = { version = "1", features = ["use-std"], optional = true }
thiserror = "1"
lru = { version = "0", optional = true }
safetensors = { version = "0", optional = true }
tokenizers = { workspace = true }

[dev-dependencies]
tokio = { version = "1", features = ["full"] }
kalosm = { workspace = true, features = ["language"] }
kalosm-learning = { workspace = true }

[features]
default = ["cache"]
remote = ["async-openai"]
serde = ["dep:serde", "safetensors"]
cache = ["serde", "dep:postcard", "dep:lru"]

[package.metadata.docs.rs]
# Features to pass to Cargo (default: [])
features = ["remote"]
