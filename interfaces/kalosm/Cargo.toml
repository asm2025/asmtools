[package]
name = "kalosm"
version = "0.2.2"
edition = "2021"
description = "A simple interface for pretrained AI models "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["llm", "llama", "whisper", "ocr", "nlp"]

[dependencies]
kalosm-common = { version = "0", path = "../kalosm-common" }
# kalosm-language = { default-features = false, workspace = true, optional = true }
kalosm-sound = { workspace = true, optional = true }
kalosm-vision = { workspace = true, optional = true }
kalosm-streams = { workspace = true }
llm-samplers = { workspace = true }
tokio = { version = "1", features = ["full", "macros", "rt-multi-thread"] }
futures-util = "0"
anyhow = "1"
rand = "0"
image = "0"
tracing = "0"
async-trait = "0"
hdrhistogram = "7"
num-traits = "0"
once_cell = "1"
comfy-table = "7"
serde = { version = "1", features = ["derive"] }
surrealdb = { version = "1", features = ["kv-rocksdb"], optional = true }

[dev-dependencies]
axum = "0"
tracing-subscriber = "0"
tokenizers = "0"
candle-core = { workspace = true }
candle-nn = { workspace = true }
candle-datasets = { workspace = true }
candle-transformers = { workspace = true }
scraper = "0"
ego-tree = "0"
kalosm-llama = { workspace = true }

[features]
default = ["sound", "vision"] #["language", "sound", "vision", "surrealdb"]
llamacpp = [] #["kalosm-language/llamacpp"]
metal = ["kalosm-vision/metal", "kalosm-sound/metal"] #["kalosm-language/metal", "kalosm-vision/metal", "kalosm-sound/metal"]
cublas = [] #["kalosm-language/cublas"]
mkl = ["kalosm-vision/mkl", "kalosm-sound/mkl"] #["kalosm-language/mkl", "kalosm-vision/mkl", "kalosm-sound/mkl"]
# language = ["kalosm-language"]
sound = ["kalosm-sound"]
vision = ["kalosm-vision"]
surrealdb = ["dep:surrealdb"]
