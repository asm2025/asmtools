[package]
name = "kalosm-sample"
version = "0.2.1"
edition = "2021"
description = "A common interface for token sampling and helpers for structered llm sampling "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["ai", "llm", "llama", "mistral", "nlp"]

[dependencies]
llm-samplers = { workspace = true }
rand = "0"
anyhow = "1"
tracing = "0"
# llm = { git = "https://github.com/rustformers/llm", optional = true }
candle-core = { workspace = true }
tokenizers = { version = "0" }
rustc-hash = "1"
regex-automata = "0"

[features]
llamacpp = []
