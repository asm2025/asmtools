[package]
name = "kalosm-sample"
version = "0.2.1"
edition = "2021"
description = "A common interface for token sampling and helpers for structered llm sampling "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["ai", "llm", "llama", "mistral", "nlp"]

[dependencies]
llm-samplers = { workspace = true }
rand = "0"
anyhow = "1"
tracing = "0"
candle-core = { workspace = true }
tokenizers = { version = "0" }
rustc-hash = "1"
regex-automata = "0"
thiserror = "1"
