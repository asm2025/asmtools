[package]
name = "rbert"
version = "0.2.1"
edition = "2021"
description = "A simple interface for Bert embeddings "
license = "MIT/Apache-2.0"
repository = "https://github.com/floneum/floneum"
authors = ["Evan Almloff"]
keywords = ["ai", "llm", "bert", "nlp", "transformers"]

[dependencies]
candle-core = { workspace = true }
candle-nn = { workspace = true }
candle-transformers = { workspace = true }
tokenizers = { version = "0" }

accelerate-src = { version = "0", optional = true }
intel-mkl-src = { version = "0", features = [
    "mkl-static-lp64-iomp",
], optional = true }
cudarc = { version = "0", features = ["f16"], optional = true }
half = { version = "2", features = [
    "num-traits",
    "use-intrinsics",
    "rand_distr",
], optional = true }

anyhow = "1"
tracing = "0"
serde_json = "1"
async-trait = "0"
tokio = { version = "1", features = ["full"] }

kalosm-common = { workspace = true }
kalosm-language-model = { workspace = true }

[features]
accelerate = [
    "dep:accelerate-src",
    "candle-core/accelerate",
    "candle-nn/accelerate",
    "candle-transformers/accelerate",
]
cuda = ["candle-core/cuda", "candle-nn/cuda", "candle-transformers/cuda"]
cudnn = ["candle-core/cudnn"]
mkl = [
    "dep:intel-mkl-src",
    "candle-core/mkl",
    "candle-nn/mkl",
    "candle-transformers/mkl",
]
nccl = ["cuda", "cudarc/nccl", "dep:half"]
metal = ["candle-core/metal", "candle-nn/metal", "candle-transformers/metal"]
